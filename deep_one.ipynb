{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_one.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katerinavr/ml-tutes/blob/master/deep_one.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha3sIKpLYN2i",
        "colab_type": "code",
        "outputId": "8c03ced6-749c-4945-8a59-eb57767cc687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!git clone https://github.com/lukasruff/Deep-SVDD-PyTorch.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Deep-SVDD-PyTorch'...\n",
            "remote: Enumerating objects: 488, done.\u001b[K\n",
            "remote: Total 488 (delta 0), reused 0 (delta 0), pack-reused 488\u001b[K\n",
            "Receiving objects: 100% (488/488), 2.15 MiB | 13.79 MiB/s, done.\n",
            "Resolving deltas: 100% (320/320), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD29CSltMekB",
        "colab_type": "code",
        "outputId": "472ad095-1501-4047-b809-8084cc707585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd Deep-SVDD-PyTorch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Deep-SVDD-PyTorch/src/Deep-SVDD-PyTorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xgZU8VZZvOo",
        "colab_type": "code",
        "outputId": "e2f9f92a-415f-4e42-a6fc-9a46a3845f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd src"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Deep-SVDD-PyTorch/src/Deep-SVDD-PyTorch/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEHH8RS6vtU_",
        "colab_type": "code",
        "outputId": "a191b55a-3e98-455d-a11d-61093abd8253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oitx6Cv3wAF4",
        "colab_type": "code",
        "outputId": "9dd4d137-2b8b-45c8-c7ac-e2df3cccc84c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!python main.py mnist mnist_LeNet ../log/mnist_test ../data --objective one-class --lr 0.0001 --n_epochs 150 --lr_milestone 50 --batch_size 200 --weight_decay 0.5e-6 --pretrain True --ae_lr 0.0001 --ae_n_epochs 150 --ae_lr_milestone 50 --ae_batch_size 200 --ae_weight_decay 0.5e-3 --normal_class 3;"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Usage: main.py [OPTIONS] [mnist|cifar10] [mnist_Le\n",
            "               Net|cifar10_LeNet|cifar10_LeNet_ELU\n",
            "               ] XP_PATH DATA_PATH\n",
            "Try \"main.py --help\" for help.\n",
            "\n",
            "Error: Invalid value for \"XP_PATH\": Path \"../log/mnist_test\" does not exist.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kxz-zzzZPYJ",
        "colab_type": "code",
        "outputId": "29ac57fe-dec1-490f-aefc-7205b8770447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "from sklearn import datasets, metrics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from sklearn.semi_supervised import label_propagation\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "np.seterr(divide='ignore', invalid='ignore')\n",
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "link = 'https://drive.google.com/open?id=10TDVemIVsZYCtdEQsF4TVdYpZOeaEnAl'\n",
        "fluff, id = link.split('=')\n",
        "print (id) # Verify that you have everything after '='\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('colab_test.csv')  \n",
        "data = pd.read_csv('colab_test.csv')\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10TDVemIVsZYCtdEQsF4TVdYpZOeaEnAl\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NAME</th>\n",
              "      <th>MW</th>\n",
              "      <th>ZM1V</th>\n",
              "      <th>DBI</th>\n",
              "      <th>Xt</th>\n",
              "      <th>MSD</th>\n",
              "      <th>ICR</th>\n",
              "      <th>PW5</th>\n",
              "      <th>MWC01</th>\n",
              "      <th>TPC</th>\n",
              "      <th>X3A</th>\n",
              "      <th>IDDE</th>\n",
              "      <th>Xindex</th>\n",
              "      <th>Yindex</th>\n",
              "      <th>CIC0</th>\n",
              "      <th>SpMax_A</th>\n",
              "      <th>VE1_A</th>\n",
              "      <th>VE2_D</th>\n",
              "      <th>VE1_X</th>\n",
              "      <th>VE2_D/Dt</th>\n",
              "      <th>SM1_Dz(Z)</th>\n",
              "      <th>WiA_Dz(v)</th>\n",
              "      <th>Chi_Dz(v)</th>\n",
              "      <th>WiA_Dz(p)</th>\n",
              "      <th>HyWi_B(m)</th>\n",
              "      <th>EE_B(m)</th>\n",
              "      <th>VE1_B(m)</th>\n",
              "      <th>VE1_B(v)</th>\n",
              "      <th>SpDiam_B(p)</th>\n",
              "      <th>HyWi_B(s)</th>\n",
              "      <th>EE_B(s)</th>\n",
              "      <th>GATS7m</th>\n",
              "      <th>GATS8m</th>\n",
              "      <th>GATS7v</th>\n",
              "      <th>GATS8v</th>\n",
              "      <th>GATS7e</th>\n",
              "      <th>GATS7p</th>\n",
              "      <th>GATS8p</th>\n",
              "      <th>GATS7i</th>\n",
              "      <th>GATS8i</th>\n",
              "      <th>GATS7s</th>\n",
              "      <th>GGI2</th>\n",
              "      <th>JGI5</th>\n",
              "      <th>JGI7</th>\n",
              "      <th>JGI8</th>\n",
              "      <th>SpMax4_Bh(m)</th>\n",
              "      <th>SpMax5_Bh(m)</th>\n",
              "      <th>SpMax2_Bh(v)</th>\n",
              "      <th>SpMax4_Bh(v)</th>\n",
              "      <th>SpMax2_Bh(p)</th>\n",
              "      <th>SpMax5_Bh(s)</th>\n",
              "      <th>SpMax7_Bh(s)</th>\n",
              "      <th>SpMin2_Bh(m)</th>\n",
              "      <th>SpMin3_Bh(m)</th>\n",
              "      <th>SpMin3_Bh(v)</th>\n",
              "      <th>SpMin2_Bh(s)</th>\n",
              "      <th>SpMaxA_EA(ed)</th>\n",
              "      <th>SpMax_AEA(dm)</th>\n",
              "      <th>SM02_AEA(dm)</th>\n",
              "      <th>SM11_AEA(dm)</th>\n",
              "      <th>SM12_AEA(dm)</th>\n",
              "      <th>Eig02_AEA(dm)</th>\n",
              "      <th>Eig08_AEA(dm)</th>\n",
              "      <th>Ui</th>\n",
              "      <th>DLS_01</th>\n",
              "      <th>LLS_01</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lab1</td>\n",
              "      <td>839.800000</td>\n",
              "      <td>478.000000</td>\n",
              "      <td>6.164000</td>\n",
              "      <td>-0.291000</td>\n",
              "      <td>3.869000</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>1.946000</td>\n",
              "      <td>5.091000</td>\n",
              "      <td>-0.11300</td>\n",
              "      <td>2.193000</td>\n",
              "      <td>-0.432000</td>\n",
              "      <td>-1.030000</td>\n",
              "      <td>2.676000</td>\n",
              "      <td>0.6460</td>\n",
              "      <td>3.704000</td>\n",
              "      <td>-0.087896</td>\n",
              "      <td>4.02300</td>\n",
              "      <td>-0.113422</td>\n",
              "      <td>2.464000</td>\n",
              "      <td>2.088000</td>\n",
              "      <td>-0.63500</td>\n",
              "      <td>1.223000</td>\n",
              "      <td>2.303000</td>\n",
              "      <td>2.784000</td>\n",
              "      <td>4.15400</td>\n",
              "      <td>3.87800</td>\n",
              "      <td>1.038000</td>\n",
              "      <td>1.913000</td>\n",
              "      <td>1.759000</td>\n",
              "      <td>1.149000</td>\n",
              "      <td>0.802000</td>\n",
              "      <td>1.012000</td>\n",
              "      <td>0.927000</td>\n",
              "      <td>1.572000</td>\n",
              "      <td>0.801000</td>\n",
              "      <td>1.043000</td>\n",
              "      <td>0.973000</td>\n",
              "      <td>0.954000</td>\n",
              "      <td>2.043000</td>\n",
              "      <td>9.333000</td>\n",
              "      <td>0.077000</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.008000</td>\n",
              "      <td>3.528000</td>\n",
              "      <td>2.987000</td>\n",
              "      <td>1.481000</td>\n",
              "      <td>2.82100</td>\n",
              "      <td>2.279000</td>\n",
              "      <td>2.409000</td>\n",
              "      <td>3.361000</td>\n",
              "      <td>0.537000</td>\n",
              "      <td>0.521000</td>\n",
              "      <td>0.629000</td>\n",
              "      <td>1.391000</td>\n",
              "      <td>-0.328000</td>\n",
              "      <td>1.935000</td>\n",
              "      <td>2.899000</td>\n",
              "      <td>13.969000</td>\n",
              "      <td>13.591000</td>\n",
              "      <td>2.855000</td>\n",
              "      <td>2.89900</td>\n",
              "      <td>-2.00000</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lab2</td>\n",
              "      <td>105.600000</td>\n",
              "      <td>204.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.117000</td>\n",
              "      <td>-0.484000</td>\n",
              "      <td>-0.579000</td>\n",
              "      <td>-0.066000</td>\n",
              "      <td>-0.431000</td>\n",
              "      <td>-2.131000</td>\n",
              "      <td>0.05000</td>\n",
              "      <td>-2.125000</td>\n",
              "      <td>0.383000</td>\n",
              "      <td>1.002000</td>\n",
              "      <td>-1.613000</td>\n",
              "      <td>-0.1550</td>\n",
              "      <td>-0.171000</td>\n",
              "      <td>-0.002680</td>\n",
              "      <td>-0.03100</td>\n",
              "      <td>-0.005946</td>\n",
              "      <td>1.384000</td>\n",
              "      <td>0.208000</td>\n",
              "      <td>-0.12000</td>\n",
              "      <td>0.976000</td>\n",
              "      <td>0.637000</td>\n",
              "      <td>2.471000</td>\n",
              "      <td>-0.38800</td>\n",
              "      <td>-0.18500</td>\n",
              "      <td>-0.269000</td>\n",
              "      <td>0.962000</td>\n",
              "      <td>3.599000</td>\n",
              "      <td>-1.016000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.016000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.016000</td>\n",
              "      <td>-1.016000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.016000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.219000</td>\n",
              "      <td>0.889000</td>\n",
              "      <td>-0.016000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023000</td>\n",
              "      <td>-0.147000</td>\n",
              "      <td>-0.739000</td>\n",
              "      <td>-1.35500</td>\n",
              "      <td>-0.641000</td>\n",
              "      <td>0.718000</td>\n",
              "      <td>-0.339000</td>\n",
              "      <td>-1.247000</td>\n",
              "      <td>-1.044000</td>\n",
              "      <td>-0.676000</td>\n",
              "      <td>-1.204000</td>\n",
              "      <td>0.251000</td>\n",
              "      <td>0.367000</td>\n",
              "      <td>-2.150000</td>\n",
              "      <td>-1.322000</td>\n",
              "      <td>-0.041000</td>\n",
              "      <td>0.448000</td>\n",
              "      <td>-1.34300</td>\n",
              "      <td>-1.39200</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.160000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lab3</td>\n",
              "      <td>1686.090000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>7.895000</td>\n",
              "      <td>-0.359000</td>\n",
              "      <td>9.659000</td>\n",
              "      <td>2.327000</td>\n",
              "      <td>0.038000</td>\n",
              "      <td>2.811000</td>\n",
              "      <td>8.387000</td>\n",
              "      <td>-0.06200</td>\n",
              "      <td>1.312000</td>\n",
              "      <td>-0.712000</td>\n",
              "      <td>-1.723000</td>\n",
              "      <td>3.131000</td>\n",
              "      <td>0.4560</td>\n",
              "      <td>5.727000</td>\n",
              "      <td>-0.120680</td>\n",
              "      <td>8.10300</td>\n",
              "      <td>-0.153946</td>\n",
              "      <td>2.485000</td>\n",
              "      <td>8.492000</td>\n",
              "      <td>-0.74100</td>\n",
              "      <td>9.553000</td>\n",
              "      <td>2.986000</td>\n",
              "      <td>3.352000</td>\n",
              "      <td>4.25900</td>\n",
              "      <td>6.85300</td>\n",
              "      <td>0.961000</td>\n",
              "      <td>3.415000</td>\n",
              "      <td>5.231000</td>\n",
              "      <td>1.091000</td>\n",
              "      <td>0.956000</td>\n",
              "      <td>0.927000</td>\n",
              "      <td>0.933000</td>\n",
              "      <td>1.518000</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>0.979000</td>\n",
              "      <td>0.942000</td>\n",
              "      <td>0.994000</td>\n",
              "      <td>1.445000</td>\n",
              "      <td>20.889000</td>\n",
              "      <td>0.036000</td>\n",
              "      <td>0.018000</td>\n",
              "      <td>0.012000</td>\n",
              "      <td>2.535000</td>\n",
              "      <td>3.679000</td>\n",
              "      <td>0.986000</td>\n",
              "      <td>1.71700</td>\n",
              "      <td>1.029000</td>\n",
              "      <td>5.726000</td>\n",
              "      <td>6.529000</td>\n",
              "      <td>0.482000</td>\n",
              "      <td>0.854000</td>\n",
              "      <td>0.982000</td>\n",
              "      <td>0.681000</td>\n",
              "      <td>-0.780000</td>\n",
              "      <td>2.678000</td>\n",
              "      <td>3.386000</td>\n",
              "      <td>9.651000</td>\n",
              "      <td>10.434000</td>\n",
              "      <td>3.754000</td>\n",
              "      <td>5.24800</td>\n",
              "      <td>3.72800</td>\n",
              "      <td>-0.750000</td>\n",
              "      <td>-0.830000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lab4</td>\n",
              "      <td>-16.145978</td>\n",
              "      <td>-118.515379</td>\n",
              "      <td>1.481367</td>\n",
              "      <td>-0.076122</td>\n",
              "      <td>0.183183</td>\n",
              "      <td>0.506108</td>\n",
              "      <td>0.047077</td>\n",
              "      <td>0.307804</td>\n",
              "      <td>0.031878</td>\n",
              "      <td>-0.03947</td>\n",
              "      <td>0.038107</td>\n",
              "      <td>0.091082</td>\n",
              "      <td>0.281758</td>\n",
              "      <td>1.261976</td>\n",
              "      <td>0.2263</td>\n",
              "      <td>0.219062</td>\n",
              "      <td>-0.012576</td>\n",
              "      <td>0.48875</td>\n",
              "      <td>-0.017368</td>\n",
              "      <td>-0.288269</td>\n",
              "      <td>0.642088</td>\n",
              "      <td>-0.33976</td>\n",
              "      <td>0.408453</td>\n",
              "      <td>0.224018</td>\n",
              "      <td>0.074431</td>\n",
              "      <td>0.11444</td>\n",
              "      <td>0.20434</td>\n",
              "      <td>0.316515</td>\n",
              "      <td>0.106187</td>\n",
              "      <td>-0.321295</td>\n",
              "      <td>0.267941</td>\n",
              "      <td>0.000302</td>\n",
              "      <td>0.310088</td>\n",
              "      <td>0.031889</td>\n",
              "      <td>0.254907</td>\n",
              "      <td>0.276119</td>\n",
              "      <td>0.003769</td>\n",
              "      <td>0.274116</td>\n",
              "      <td>-0.003564</td>\n",
              "      <td>0.470759</td>\n",
              "      <td>0.561294</td>\n",
              "      <td>0.022727</td>\n",
              "      <td>-0.003638</td>\n",
              "      <td>-0.002659</td>\n",
              "      <td>0.825225</td>\n",
              "      <td>1.084745</td>\n",
              "      <td>0.231676</td>\n",
              "      <td>1.00226</td>\n",
              "      <td>0.168257</td>\n",
              "      <td>0.808882</td>\n",
              "      <td>1.429276</td>\n",
              "      <td>0.300853</td>\n",
              "      <td>0.416853</td>\n",
              "      <td>0.424089</td>\n",
              "      <td>0.404697</td>\n",
              "      <td>0.063067</td>\n",
              "      <td>0.686208</td>\n",
              "      <td>-0.260492</td>\n",
              "      <td>2.454443</td>\n",
              "      <td>3.294731</td>\n",
              "      <td>0.673106</td>\n",
              "      <td>-0.34207</td>\n",
              "      <td>-0.71864</td>\n",
              "      <td>-0.111236</td>\n",
              "      <td>-0.153835</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lab5</td>\n",
              "      <td>-1394.090000</td>\n",
              "      <td>-1186.000000</td>\n",
              "      <td>-7.660000</td>\n",
              "      <td>0.355000</td>\n",
              "      <td>-8.077000</td>\n",
              "      <td>-1.788000</td>\n",
              "      <td>-0.043000</td>\n",
              "      <td>-2.749000</td>\n",
              "      <td>-8.334000</td>\n",
              "      <td>0.07700</td>\n",
              "      <td>-1.419000</td>\n",
              "      <td>0.696000</td>\n",
              "      <td>1.677000</td>\n",
              "      <td>-3.706000</td>\n",
              "      <td>-0.5140</td>\n",
              "      <td>-6.264000</td>\n",
              "      <td>0.108104</td>\n",
              "      <td>-6.84000</td>\n",
              "      <td>0.136578</td>\n",
              "      <td>-0.944000</td>\n",
              "      <td>-7.018000</td>\n",
              "      <td>0.71800</td>\n",
              "      <td>-7.524000</td>\n",
              "      <td>-2.764000</td>\n",
              "      <td>-2.833000</td>\n",
              "      <td>-6.06100</td>\n",
              "      <td>-6.00600</td>\n",
              "      <td>-0.890000</td>\n",
              "      <td>-2.897000</td>\n",
              "      <td>-4.041000</td>\n",
              "      <td>-0.985000</td>\n",
              "      <td>-0.904000</td>\n",
              "      <td>-1.080000</td>\n",
              "      <td>-0.774000</td>\n",
              "      <td>-0.589000</td>\n",
              "      <td>-1.118000</td>\n",
              "      <td>-0.738000</td>\n",
              "      <td>-1.258000</td>\n",
              "      <td>-0.782000</td>\n",
              "      <td>-0.466000</td>\n",
              "      <td>-15.556000</td>\n",
              "      <td>-0.029000</td>\n",
              "      <td>-0.014000</td>\n",
              "      <td>-0.010000</td>\n",
              "      <td>-1.733000</td>\n",
              "      <td>-2.840000</td>\n",
              "      <td>-0.993000</td>\n",
              "      <td>-1.66600</td>\n",
              "      <td>-0.961000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-3.620000</td>\n",
              "      <td>-0.544000</td>\n",
              "      <td>-0.916000</td>\n",
              "      <td>-0.975000</td>\n",
              "      <td>-0.726000</td>\n",
              "      <td>0.771000</td>\n",
              "      <td>-1.317000</td>\n",
              "      <td>-3.230000</td>\n",
              "      <td>-9.909000</td>\n",
              "      <td>-10.692000</td>\n",
              "      <td>-2.392000</td>\n",
              "      <td>-3.45900</td>\n",
              "      <td>-3.28500</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   NAME           MW         ZM1V       DBI  ...       Ui    DLS_01    LLS_01  label\n",
              "0  lab1   839.800000   478.000000  6.164000  ... -2.00000 -0.250000 -0.500000      1\n",
              "1  lab2   105.600000   204.000000  0.000000  ... -1.39200  0.000000 -0.160000      1\n",
              "2  lab3  1686.090000  2010.000000  7.895000  ...  3.72800 -0.750000 -0.830000      1\n",
              "3  lab4   -16.145978  -118.515379  1.481367  ... -0.71864 -0.111236 -0.153835      1\n",
              "4  lab5 -1394.090000 -1186.000000 -7.660000  ... -3.28500  0.500000  0.830000      1\n",
              "\n",
              "[5 rows x 67 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhaS3jFtYbLe",
        "colab_type": "code",
        "outputId": "3066e9d9-ac55-4183-a3e9-32c1691ddadd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "df1 = data.iloc[:1351, :]\n",
        "df2 = data.iloc[1351:, :]\n",
        "\n",
        "df_1 = data.iloc[:1351, 1:-1]\n",
        "df_2 = data.iloc[1351:,1:-1]\n",
        "\n",
        "df_1.values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 8.39800e+02,  4.78000e+02,  6.16400e+00, ..., -2.00000e+00,\n",
              "        -2.50000e-01, -5.00000e-01],\n",
              "       [ 1.05600e+02,  2.04000e+02,  0.00000e+00, ..., -1.39200e+00,\n",
              "         0.00000e+00, -1.60000e-01],\n",
              "       [ 1.68609e+03,  2.01000e+03,  7.89500e+00, ...,  3.72800e+00,\n",
              "        -7.50000e-01, -8.30000e-01],\n",
              "       ...,\n",
              "       [ 4.63340e+02,  4.94000e+02,  3.24000e+00, ...,  2.42600e+00,\n",
              "        -5.00000e-01, -5.00000e-01],\n",
              "       [ 3.29440e+02,  3.54000e+02,  3.16200e+00, ...,  1.32200e+00,\n",
              "         0.00000e+00, -6.70000e-01],\n",
              "       [-1.53910e+02, -4.34000e+02, -2.33000e+00, ..., -8.30000e-01,\n",
              "         0.00000e+00,  6.60000e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp2H--MVaqRi",
        "colab_type": "code",
        "outputId": "57d8e1f9-a28f-44cf-bbe4-348424e029a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "tensor=[]\n",
        "\n",
        "for i in range(df_1.shape[0]):\n",
        "    #df_1.iloc[i] = torch.tensor(df_1[:], dtype=torch.float)\n",
        "    b= torch.from_numpy(df_1.iloc[i].values)\n",
        "    #tensor.view(1, 65)\n",
        "    tensor.append(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d6cc7e2f7122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#df_1.iloc[i] = torch.tensor(df_1[:], dtype=torch.float)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m#tensor.view(1, 65)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qnCuX1fau7t",
        "colab_type": "code",
        "outputId": "c26e1029-527b-4eee-ba93-c29c950eddad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(tensor)\n",
        "\n",
        "for i in range(0, len(tensor)):\n",
        "  tensor[i]= tensor[i].view(1,65)\n",
        "  \n",
        "tensor[1].size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function Tensor.size>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIbBCRjRiR8c",
        "colab_type": "code",
        "outputId": "d53c0b4b-bf53-46ed-b413-faf22fe32ac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "tensor[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 8.3980e+02,  4.7800e+02,  6.1640e+00, -2.9100e-01,  3.8690e+00,\n",
              "          1.4740e+00,  4.0000e-03,  1.9460e+00,  5.0910e+00, -1.1300e-01,\n",
              "          2.1930e+00, -4.3200e-01, -1.0300e+00,  2.6760e+00,  6.4600e-01,\n",
              "          3.7040e+00, -8.7896e-02,  4.0230e+00, -1.1342e-01,  2.4640e+00,\n",
              "          2.0880e+00, -6.3500e-01,  1.2230e+00,  2.3030e+00,  2.7840e+00,\n",
              "          4.1540e+00,  3.8780e+00,  1.0380e+00,  1.9130e+00,  1.7590e+00,\n",
              "          1.1490e+00,  8.0200e-01,  1.0120e+00,  9.2700e-01,  1.5720e+00,\n",
              "          8.0100e-01,  1.0430e+00,  9.7300e-01,  9.5400e-01,  2.0430e+00,\n",
              "          9.3330e+00,  7.7000e-02,  4.0000e-02,  8.0000e-03,  3.5280e+00,\n",
              "          2.9870e+00,  1.4810e+00,  2.8210e+00,  2.2790e+00,  2.4090e+00,\n",
              "          3.3610e+00,  5.3700e-01,  5.2100e-01,  6.2900e-01,  1.3910e+00,\n",
              "         -3.2800e-01,  1.9350e+00,  2.8990e+00,  1.3969e+01,  1.3591e+01,\n",
              "          2.8550e+00,  2.8990e+00, -2.0000e+00, -2.5000e-01, -5.0000e-01]],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmsYU4CR1Z8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class BaseNet(nn.Module):\n",
        "    \"\"\"Base class for all neural networks.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "        self.rep_dim = None  # representation dimensionality, i.e. dim of the last layer\n",
        "\n",
        "    def forward(self, *input):\n",
        "        \"\"\"\n",
        "        Forward pass logic\n",
        "        :return: Network output\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def summary(self):\n",
        "        \"\"\"Network summary.\"\"\"\n",
        "        net_parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
        "        params = sum([np.prod(p.size()) for p in net_parameters])\n",
        "        self.logger.info('Trainable parameters: {}'.format(params))\n",
        "        self.logger.info(self)\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeHFT4Ok2Nnz",
        "colab_type": "code",
        "outputId": "fa7fb657-33ff-4535-cf0b-7638d4f0d1cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from base.base_net import BaseNet\n",
        "\n",
        "\n",
        "class Net(BaseNet):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.rep_dim = 10\n",
        "        self.pool = nn.MaxPool2d(1, 2)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 8, 5, bias=False, padding=2)\n",
        "        #self.bn1 = nn.BatchNorm2d(8, eps=1e-04, affine=False)\n",
        "        self.conv2 = nn.Conv2d(8, 4, 5, bias=False, padding=2)\n",
        "        #self.bn2 = nn.BatchNorm2d(4, eps=1e-04, affine=False)\n",
        "        self.fc1 = nn.Linear(65, self.rep_dim, bias=False)\n",
        "        self.fc2 = nn.Linear(self.rep_dim, 2, bias=False)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu((self.fc1(input)))\n",
        "        x = F.softmax(self.fc2(x), dim=1)\n",
        "        #x = self.conv1(x)\n",
        "        #x = self.pool(F.leaky_relu(self.fc1(x)))\n",
        "        #x = self.conv2(x)\n",
        "        #x = self.pool(F.leaky_relu(self.fc2(x)))\n",
        "        #x = x.view(x.size(0), -1)\n",
        "        #x = self.fc1(x)\n",
        "        return x\n",
        "net = Net()\n",
        "print(net)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MNIST_LeNet_Autoencoder(BaseNet):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.rep_dim = 63\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Encoder (must match the Deep SVDD network above)\n",
        "        self.conv1 = nn.Conv2d(1, 8, 5, bias=False, padding=2)\n",
        "        self.bn1 = nn.BatchNorm2d(8, eps=1e-04, affine=False)\n",
        "        self.conv2 = nn.Conv2d(8, 4, 5, bias=False, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(4, eps=1e-04, affine=False)\n",
        "        self.fc1 = nn.Linear(4 * 4 * 7, self.rep_dim, bias=False)\n",
        "\n",
        "        # Decoder\n",
        "        self.conv3 = nn.Conv2d(2, 4, 5, bias=False, padding=2)\n",
        "        self.bn3 = nn.BatchNorm2d(4, eps=1e-04, affine=False)\n",
        "        self.conv4 = nn.Conv2d(4, 8, 5, bias=False, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(8, eps=1e-04, affine=False)\n",
        "        self.conv5 = nn.Conv2d(8, 1, 5, bias=False, padding=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool(F.leaky_relu(self.bn1(x)))\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool(F.leaky_relu(self.bn2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = x.view(x.size(0), int(self.rep_dim / 16), 4, 4)\n",
        "        x = F.interpolate(F.leaky_relu(x), scale_factor=2)\n",
        "        x = self.conv3(x)\n",
        "        x = F.interpolate(F.leaky_relu(self.bn3(x)), scale_factor=2)\n",
        "        x = self.conv4(x)\n",
        "        x = F.interpolate(F.leaky_relu(self.bn4(x)), scale_factor=2)\n",
        "        x = self.conv5(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (pool): MaxPool2d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "  (conv2): Conv2d(8, 4, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "  (fc1): Linear(in_features=65, out_features=10, bias=False)\n",
            "  (fc2): Linear(in_features=10, out_features=2, bias=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE9k8Hb23RE5",
        "colab_type": "code",
        "outputId": "cc18f8d8-9f6a-4aa3-c1b2-065dd53332e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "torch.Size([8, 1, 5, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nJrHYzWHi9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(network, self).__init__()\n",
        "        self.linear1 = nn.Linear(in_features=65, out_features=32)\n",
        "        #self.bn1 = nn.BatchNorm1d(num_features=320)\n",
        "        self.linear2 = nn.Linear(in_features=32, out_features=2)\n",
        "\n",
        "    def forward(self, input):  # Input is a 1D tensor\n",
        "        y = F.relu((self.linear1(input)))\n",
        "        y = F.softmax(self.linear2(y), dim=1)\n",
        "        return y\n",
        "    \n",
        "model = network()\n",
        "x = torch.from_numpy(df_1.iloc[i].values).view(1,65).float()\n",
        "#torch.from_numpy(df_1.iloc[i].values).view(1,65)\n",
        "output = model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzMuyShg3hfE",
        "colab_type": "code",
        "outputId": "c53b1fff-da9e-4182-f3a9-485bcb87f896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input = torch.from_numpy(df_1.iloc[i].values).view(1,65).float()\n",
        "out = net(input)\n",
        "print(out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.0000e+00, 1.4420e-07]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXifRdG82I5X",
        "colab_type": "code",
        "outputId": "4fa53b46-6f44-4ec4-848e-7fe78377d9c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-6153aad8ac0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JL0NbvrfHW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Autoencoder:\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "        super().__init__()\n",
        "\n",
        "        self.rep_dim = 65\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Encoder (must match the Deep SVDD network above)\n",
        "        self.conv1 = nn.Conv2d(1, 8, 5, bias=False, padding=2)\n",
        "        self.bn1 = nn.BatchNorm2d(8, eps=1e-04, affine=False)\n",
        "        self.conv2 = nn.Conv2d(8, 4, 5,  bias=False, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(4, eps=1e-04, affine=False)\n",
        "        self.fc1 = nn.Linear(4 * 7 , self.rep_dim, bias=False)\n",
        "\n",
        "        # Decoder\n",
        "        self.deconv1 = nn.ConvTranspose2d(2, 4, 5,  bias=False, padding=2)\n",
        "        self.bn3 = nn.BatchNorm2d(4, eps=1e-04, affine=False)\n",
        "        self.deconv2 = nn.ConvTranspose2d(4, 8, 5,  bias=False, padding=3)\n",
        "        self.bn4 = nn.BatchNorm2d(8, eps=1e-04, affine=False)\n",
        "        self.deconv3 = nn.ConvTranspose2d(8, 1, 5, bias=False, padding=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool(F.leaky_relu(self.bn1(x)))\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool(F.leaky_relu(self.bn2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = x.view(x.size(0), int(self.rep_dim / 16), 4, 4)\n",
        "        x = F.interpolate(F.leaky_relu(x), scale_factor=2)\n",
        "        x = self.deconv1(x)\n",
        "        x = F.interpolate(F.leaky_relu(self.bn3(x)), scale_factor=2)\n",
        "        x = self.deconv2(x)\n",
        "        x = F.interpolate(F.leaky_relu(self.bn4(x)), scale_factor=2)\n",
        "        x = self.deconv3(x)\n",
        "        x = torch.sigmoid(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofdBYQU1ekkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_autoencoder(net_name):\n",
        "    \"\"\"Builds the corresponding autoencoder network.\"\"\"\n",
        "\n",
        "    implemented_networks = ('mnist_LeNet', 'dataset')\n",
        "    assert net_name in implemented_networks\n",
        "\n",
        "    ae_net = None\n",
        "\n",
        "    if net_name == 'mnist_LeNet':\n",
        "        ae_net = MNIST_LeNet_Autoencoder()\n",
        "\n",
        "    if net_name == 'dataset':\n",
        "        ae_net = Autoencoder()\n",
        "\n",
        "    return ae_net\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZG3vQRPXvp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import torch\n",
        "\n",
        "from base.base_dataset import BaseADDataset\n",
        "from networks.main import build_network, build_autoencoder\n",
        "from optim.deepSVDD_trainer import DeepSVDDTrainer\n",
        "from optim.ae_trainer import AETrainer\n",
        "\n",
        "dataset = tensor \n",
        "\n",
        "class DeepSVDD:\n",
        "    \"\"\"A class for the Deep SVDD method.\n",
        "    Attributes:\n",
        "        objective: A string specifying the Deep SVDD objective (either 'one-class' or 'soft-boundary').\n",
        "        nu: Deep SVDD hyperparameter nu (must be 0 < nu <= 1).\n",
        "        R: Hypersphere radius R.\n",
        "        c: Hypersphere center c.\n",
        "        net_name: A string indicating the name of the neural network to use.\n",
        "        net: The neural network \\phi.\n",
        "        ae_net: The autoencoder network corresponding to \\phi for network weights pretraining.\n",
        "        trainer: DeepSVDDTrainer to train a Deep SVDD model.\n",
        "        optimizer_name: A string indicating the optimizer to use for training the Deep SVDD network.\n",
        "        ae_trainer: AETrainer to train an autoencoder in pretraining.\n",
        "        ae_optimizer_name: A string indicating the optimizer to use for pretraining the autoencoder.\n",
        "        results: A dictionary to save the results.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, objective: str = 'one-class', nu: float = 0.1):\n",
        "        \"\"\"Inits DeepSVDD with one of the two objectives and hyperparameter nu.\"\"\"\n",
        "\n",
        "        assert objective in ('one-class', 'soft-boundary'), \"Objective must be either 'one-class' or 'soft-boundary'.\"\n",
        "        self.objective = objective\n",
        "        assert (0 < nu) & (nu <= 1), \"For hyperparameter nu, it must hold: 0 < nu <= 1.\"\n",
        "        self.nu = nu\n",
        "        self.R = 0.0  # hypersphere radius R\n",
        "        self.c = None  # hypersphere center c\n",
        "\n",
        "        self.net_name = None\n",
        "        self.net = None  # neural network \\phi\n",
        "\n",
        "        self.trainer = None\n",
        "        self.optimizer_name = None\n",
        "\n",
        "        self.ae_net = None  # autoencoder network for pretraining\n",
        "        self.ae_trainer = None\n",
        "        self.ae_optimizer_name = None\n",
        "\n",
        "        self.results = {\n",
        "            'train_time': None,\n",
        "            'test_auc': None,\n",
        "            'test_time': None,\n",
        "            'test_scores': None,\n",
        "        }\n",
        "\n",
        "    def set_network(self, net_name):\n",
        "        \"\"\"Builds the neural network \\phi.\"\"\"\n",
        "        self.net_name = net_name\n",
        "        self.net = build_network(net_name)\n",
        "\n",
        "    def train(self, dataset: BaseADDataset, optimizer_name: str = 'adam', lr: float = 0.001, n_epochs: int = 50,\n",
        "              lr_milestones: tuple = (), batch_size: int = 128, weight_decay: float = 1e-6, device: str = 'cuda',\n",
        "              n_jobs_dataloader: int = 0):\n",
        "        \"\"\"Trains the Deep SVDD model on the training data.\"\"\"\n",
        "\n",
        "        self.optimizer_name = optimizer_name\n",
        "        self.trainer = DeepSVDDTrainer(self.objective, self.R, self.c, self.nu, optimizer_name, lr=lr,\n",
        "                                       n_epochs=n_epochs, lr_milestones=lr_milestones, batch_size=batch_size,\n",
        "                                       weight_decay=weight_decay, device=device, n_jobs_dataloader=n_jobs_dataloader)\n",
        "        # Get the model\n",
        "        self.net = self.trainer.train(dataset, self.net)\n",
        "        self.R = float(self.trainer.R.cpu().data.numpy())  # get float\n",
        "        self.c = self.trainer.c.cpu().data.numpy().tolist()  # get list\n",
        "        self.results['train_time'] = self.trainer.train_time\n",
        "\n",
        "    def test(self, dataset: BaseADDataset, device: str = 'cuda', n_jobs_dataloader: int = 0):\n",
        "        \"\"\"Tests the Deep SVDD model on the test data.\"\"\"\n",
        "\n",
        "        if self.trainer is None:\n",
        "            self.trainer = DeepSVDDTrainer(self.objective, self.R, self.c, self.nu,\n",
        "                                           device=device, n_jobs_dataloader=n_jobs_dataloader)\n",
        "\n",
        "        self.trainer.test(dataset, self.net)\n",
        "        # Get results\n",
        "        self.results['test_auc'] = self.trainer.test_auc\n",
        "        self.results['test_time'] = self.trainer.test_time\n",
        "        self.results['test_scores'] = self.trainer.test_scores\n",
        "\n",
        "    def pretrain(self, optimizer_name: str = 'adam', lr: float = 0.001, n_epochs: int = 100,\n",
        "                 lr_milestones: tuple = (), batch_size: int = 128, weight_decay: float = 1e-6, device: str = 'cuda',\n",
        "                 n_jobs_dataloader: int = 0):\n",
        "        \"\"\"Pretrains the weights for the Deep SVDD network \\phi via autoencoder.\"\"\"\n",
        "\n",
        "        self.ae_net = build_autoencoder(self.net_name)\n",
        "        self.ae_optimizer_name = optimizer_name\n",
        "        self.ae_trainer = AETrainer(optimizer_name, lr=lr, n_epochs=n_epochs, lr_milestones=lr_milestones,\n",
        "                                    batch_size=batch_size, weight_decay=weight_decay, device=device,\n",
        "                                    n_jobs_dataloader=n_jobs_dataloader)\n",
        "        self.ae_net = self.ae_trainer.train(dataset, self.ae_net)\n",
        "        self.ae_trainer.test(dataset, self.ae_net)\n",
        "        self.init_network_weights_from_pretraining()\n",
        "\n",
        "    def init_network_weights_from_pretraining(self):\n",
        "        \"\"\"Initialize the Deep SVDD network weights from the encoder weights of the pretraining autoencoder.\"\"\"\n",
        "\n",
        "        net_dict = self.net.state_dict()\n",
        "        ae_net_dict = self.ae_net.state_dict()\n",
        "\n",
        "        # Filter out decoder network keys\n",
        "        ae_net_dict = {k: v for k, v in ae_net_dict.items() if k in net_dict}\n",
        "        # Overwrite values in the existing state_dict\n",
        "        net_dict.update(ae_net_dict)\n",
        "        # Load the new state_dict\n",
        "        self.net.load_state_dict(net_dict)\n",
        "\n",
        "    def save_model(self, export_model, save_ae=True):\n",
        "        \"\"\"Save Deep SVDD model to export_model.\"\"\"\n",
        "\n",
        "        net_dict = self.net.state_dict()\n",
        "        ae_net_dict = self.ae_net.state_dict() if save_ae else None\n",
        "\n",
        "        torch.save({'R': self.R,\n",
        "                    'c': self.c,\n",
        "                    'net_dict': net_dict,\n",
        "                    'ae_net_dict': ae_net_dict}, export_model)\n",
        "\n",
        "    def load_model(self, model_path, load_ae=False):\n",
        "        \"\"\"Load Deep SVDD model from model_path.\"\"\"\n",
        "\n",
        "        model_dict = torch.load(model_path)\n",
        "\n",
        "        self.R = model_dict['R']\n",
        "        self.c = model_dict['c']\n",
        "        self.net.load_state_dict(model_dict['net_dict'])\n",
        "        if load_ae:\n",
        "            if self.ae_net is None:\n",
        "                self.ae_net = build_autoencoder(self.net_name)\n",
        "            self.ae_net.load_state_dict(model_dict['ae_net_dict'])\n",
        "\n",
        "    def save_results(self, export_json):\n",
        "        \"\"\"Save results dict to a JSON-file.\"\"\"\n",
        "        with open(export_json, 'w') as fp:\n",
        "            json.dump(self.results, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR4NFPH2Z7U2",
        "colab_type": "code",
        "outputId": "65149f17-77c7-408c-dfc7-38a32c366002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "DeepSVDD.pretrain(tensor)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8ca34207675c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDeepSVDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-8cc12ddc908e>\u001b[0m in \u001b[0;36mpretrain\u001b[0;34m(self, optimizer_name, lr, n_epochs, lr_milestones, batch_size, weight_decay, device, n_jobs_dataloader)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;34m\"\"\"Pretrains the weights for the Deep SVDD network \\phi via autoencoder.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mae_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_autoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mae_optimizer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         self.ae_trainer = AETrainer(optimizer_name, lr=lr, n_epochs=n_epochs, lr_milestones=lr_milestones,\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'net_name'"
          ]
        }
      ]
    }
  ]
}